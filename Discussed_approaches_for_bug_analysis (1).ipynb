{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Discussed approaches for bug analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb6FVaKvFdSJ"
      },
      "source": [
        "In this project, We discussed various approaches to find or predict the likelihood of bug in the software"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeNfGLbeIJvv"
      },
      "source": [
        "# 1.\tPerformance Analysis using Software features at Component(file) level:\n",
        "   - Uses NASA DATASET to develop a prototype\n",
        "    - refer: http://promise.site.uottawa.ca/SERepository/datasets-page.html\n",
        "   -  A software code base has many releases and many bug fixes.\n",
        "   - we extract features of previous versions and labelled whether it has  bug or not\n",
        "   - we vectorize input features and output class and train different ML algorithms\n",
        "   - So, we can predict whether a file has bug or not.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL2LHrLory8v"
      },
      "source": [
        "# 2. Rule based approach for software fault detection\n",
        "- In this approach, software features or metrics are calculated and sets some threshold values to those metrics and checks whether the values are present in acceptable range for successful  project. \n",
        "-Otherwise, it needs to be redesign.\n",
        "- Here are some examples of acceptable software features limits for a successful project.\n",
        "  ### Threshold limits.\n",
        "- From my research, I find that:<br>\n",
        "\n",
        "- According to Halstead features,\n",
        "  if a software is sucessful if its \n",
        "  1. Halstead total operators + operands n  < 300\n",
        "  2. Halstead Volume < 1000\n",
        "  3. Halstead difficulty < 50 \n",
        "  4. Halstead efforts < 500000\n",
        "  5. Halstead time < 5000\n",
        "\n",
        "Otherwise, It needs to be redesign<br>\n",
        "<br>\n",
        "So, I apply rule based  approach to find software is succesful or need to be redesign\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aaDtrVTrPqN"
      },
      "source": [
        "# 3. Software fault detection by categorizing software code as  UI and Non UI code and finds the dependency of functionalities of Non UI code.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJVc_CNv9rZw"
      },
      "source": [
        "- We assume that errors in  UI code are clearly visible and does not lead to any software failures.\n",
        "- But bugs in Non UI code(backend code) leads to software failure. \n",
        "- So, we first categorize the software code as UI and Non UI code. \n",
        "- And we calculate the dependency in that Non UI code.\n",
        "- If dependency is more, then it have more chances to lead to software faults."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzqIbFUCpDX4"
      },
      "source": [
        "# 4. bug prediction at method level\n",
        "* bug prediction models at the level of individual methods rather than at file-level\n",
        "* This increases the granularity of the prediction and thus reduces manual inspection efforts for developers\n",
        "* The models are based on change metrics and source code metrics that are typically used in bug prediction.\n",
        "-----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSlNjnoQqPpi"
      },
      "source": [
        "#5. Bug prediction using Abstract syntax tree(AST)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iz3UF0Bp_RD"
      },
      "source": [
        "\n",
        "\n",
        "<b>Objective: </b>We use Abstract Syntax Tree (AST) n-grams to identify features of defective Java code that improve defect prediction performance.\n",
        "\n",
        "<b>Method: </b>Our approach is bottom-up and does not rely on pre-selecting any specific features of code. We use non-parametric testing to determine relationships between AST n-grams and faults in both open source and commercial systems. We build defect prediction models using three machine learning techniques.\n",
        "\n",
        "<b>Results:</b>\n",
        " We show that AST n-grams are very significantly related to faults in some systems, with very large effect sizes. The occurrence of some frequently occurring AST n-grams in a method can mean that the method is up to three times more likely to contain a fault. AST n-grams can have a large effect on the performance of defect prediction models.\n",
        " \n",
        "-----------\n",
        "refer: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz-wq-ugIiOr"
      },
      "source": [
        "#6. A ML model that predicts the number of bugs that might occur while reaching the QA Stage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0MtS3f7JL8u"
      },
      "source": [
        "<b>Quality Assurance (QA) </b> is a systematic process that ensures product and service excellence. ... The agile QA process begins at the inception of the software development life cycle. From the initial design meeting, through the development phase, to final testing and hardening of the application\n",
        "\n",
        "----------\n",
        "refer : https://github.com/AravindVasudev/defect-predictor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH4XyT03Jtze"
      },
      "source": [
        "# 7. Control flow graphs for bug prediction\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Exploiting graph-structured data has many real applications in domains including natural language semantics, programming language processing, and malware analysis. A variety of methods has been developed to deal with such data. However, learning graphs of large-scale, varying shapes and sizes is a big challenge for any method. In this paper, we propose a multi-view multi-layer convolutional neural network on labeled directed graphs (DGCNN), in which convolutional filters are designed flexibly to adapt to dynamic structures of local regions inside graphs. The advantages of DGCNN are that we do not need to align vertices between graphs, and that DGCNN can process large-scale dynamic graphs with hundred thousands of nodes. To verify the effectiveness of DGCNN, we conducted experiments on two tasks: malware analysis and software defect prediction. The results show that DGCNN outperforms the baselines, including several deep neural networks\n",
        "\n",
        "-----\n",
        "refer: https://github.com/nguyenlab/DGCNN "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtwg0_pqKpR7"
      },
      "source": [
        "# 8. Software  Vulnerability Detection in Source Code Using Deep Representation Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qja7z8O3KsAd"
      },
      "source": [
        "* Increasing numbers of software vulnerabilities are discovered every year whether they are reported publicly or discovered internally in proprietary code. \n",
        "* These vulnerabilities can pose serious risk of exploit and result in system compromise, information leaks, or denial of service. \n",
        "* We leveraged the wealth of C and C++ open-source code available to develop a large-scale function-level vulnerability detection system using machine learning. \n",
        "*To supplement existing labeled vulnerability datasets, we compiled a vast dataset of millions of open-source functions and labeled it with carefully-selected findings from three different static analyzers that indicate potential exploits. The labeled dataset is available \n",
        "----------\n",
        "dataset : https://osf.io/d45bw/\n",
        "----------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIYDJ8ghMezQ"
      },
      "source": [
        "* The dataset consists of the source code of 1.27 million functions mined from open source software, labeled by static analysis for potential vulnerabilities.\n",
        "* Each function's raw source code, starting from the function name, is stored as a variable-length UTF-8 string. Five binary 'vulnerability' labels are provided for each function, corresponding to the four most common CWEs in our data plus all others:\n",
        "*CWE-120 (3.7% of functions)\n",
        "*CWE-119 (1.9% of functions)\n",
        "*CWE-469 (0.95% of functions)\n",
        "*CWE-476 (0.21% of functions)\n",
        "*CWE-other (2.7% of functions)\n",
        "*Functions may have more than one detected CWE each."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKhTYxcuL3n7"
      },
      "source": [
        " **The Common Weakness Enumeration (CWE)**\n",
        "is a category system for software weaknesses and vulnerabilities. It is sustained by a community project with the goals of understanding flaws in software and creating automated tools that can be used to identify, fix, and prevent those flaws.\n",
        "----------\n",
        "<b>CVE </b>stands for Common Vulnerabilities and Exposures\n",
        "-------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ-L95a8M2WU"
      },
      "source": [
        "refer : https://github.com/hazimhanif/svd_exp1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNrGHBDeM4z8"
      },
      "source": [
        "# Replication of AST Neural Network application for software vulnerability detection\n",
        "\n",
        "refer: https://github.com/hazimhanif/svd_exp3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irh7EMH2Nqs9"
      },
      "source": [
        "# 9. Predicting code bug risk with git metadata\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-Mq6RqSgzl4"
      },
      "source": [
        "*Git tracks changes to a codebase as a series of ‘commits’. Each commit contains a set of changes along with a unique identifier. When a new commit is recorded, git also records who made the commit, when it was recorded, and an explanatory note written by the user who made the commit.\n",
        "*  two types of metadata: commit-level data and history-level data.\n",
        "* for example, the changes in a particular file between two different points in the commit history. We need to use both types of metadata for our bug risk prediction tool, fortunately, git makes it easy to get at this information\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOhI8PVshOJp"
      },
      "source": [
        "* Git comes with several extra command line utilities that expose different bits of metadata. For this project I used three of them: git log, git diff, and git blame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgMeVn8MhepL"
      },
      "source": [
        "<b>How does the bug risk prediction work?</b>\n",
        "To predict code bug risk we want to build a model which predicts whether a given commit will introduce a bug. To build any kind of model we need labeled data,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1ZMMSl-hjCD"
      },
      "source": [
        "identify which commits introduced bugs with a four-step process:\n",
        "1. Identify all the commits which fix bugs by using git log to find all the commits which have messages that start with ‘Bug’ or ‘Fix’.\n",
        "2. Figure out what each bugfix commit modified by using git diff to compare each bugfix commit to its immediate predecessor.\n",
        "3. Find the last commit to touch the corrected lines by using git blameto inspect the corrected file as of right before the bugfix commit.\n",
        "4. Label that commit as having introduced a bug.\n",
        "\n",
        "--------\n",
        "refer : gitrisky"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b2ulN0oiiKC"
      },
      "source": [
        "# 10. Bug hot-spots based on commit history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb5rcMmri4Bz"
      },
      "source": [
        "*  we take into consideration the number of code check-ins made for bug fixes in a particular area of code. The higher the bug fixes, the higher the probability of bugs arising.\n",
        "* This approach uses an algorithm which looks at the commit history of an application and based on the number of commits for bug fixes and their recency identifies bug hot-spots and arranges them in order of decreasing risk.\n",
        "* Categorizing commits as Bug fixes or not. commit for bug fix or requirements\n",
        "\n",
        "* The algo now equipped with the data(Git commit history) in a given time frame, generates a ‘risk-score’ for all files in the code base being analyzed. Apart from the the total number of bugs, the algo also takes into account recency — weightage of the bugs decays with passing time. \n",
        "\n",
        "-------------\n",
        "refer : https://github.com/niedbalski/python-bugspots\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seZbnKg0y6sQ"
      },
      "source": [
        "##These approaches can be implemented using any \n",
        "### Traditional ML  algorthms\n",
        "### NN architectures\n",
        "### Genetic algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ7SjTJQC2n7"
      },
      "source": [
        "#### Genetic algorithms\n",
        "This document serves as a guide for the project.\n",
        "\n",
        "Basically for the project, we need to select the features that result in best classification\n",
        "There are some features that not only do not contribute anything to the classification model\n",
        "but deteriorate its performance due to random noise. As a result they should not be included\n",
        "in the model. As a result the selection of features becomes an important task.\n",
        "\n",
        "Since our aim is to create a software bug classification model, in order to manually select the\n",
        "features, we would need prior knowledge of the code. In most software projects this is not possible\n",
        "for a person to have idea about the whole project. As a result, we need to use automated tools to\n",
        "assist us in this endeavor. \n",
        "\n",
        "We use a neural network to implement the classifier using a subset of the features provided.\n",
        "Since there are so many features, we select the best features using Genetic Algorithms (GA).\n",
        "The method used in this project is as follows\n",
        "\n",
        "1. Initialize a population of subsets of features chosen at random.\n",
        "2. The genome of an individual encodes the following information\n",
        "   1. The subset of the features used.\n",
        "   2. The number of nodes in the hidden layer of the neural network.\n",
        "   3, Number of epochs to train.\n",
        "3. Individuals are trained on a subset of the training set with the remaining dataset used for\n",
        "   validation. This serves as the fitness function to determine the fit individuals that live on\n",
        "   in the next generation.\n",
        "\n",
        "This is achieved using the following code structure\n",
        "1. Organism class encodes all the information about mutation and crossovers and fitness of an \n",
        "   individual.\n",
        "2. Population class encodes all the information about managing the population (collection of \n",
        "   Organisms) from one generation to the next.\n",
        "3. GA class that uses the Population class and implements the actual Genetic Algorithm.\n",
        "4. FitnessMeasure class that uses a means of classification including but not limited to Neural\n",
        "   Networks to evaluate the fitness of an individual Organism by training the said model using \n",
        "   the parameters encoded in the Organism's genotype and returns a validation accuracy score on\n",
        "   validation dataset which is a subset of the training dataset.\n",
        "\n",
        "----\n",
        "refer :\n",
        "https://github.com/adityashah30/eecs545termproject/tree/master/code"
      ]
    }
  ]
}